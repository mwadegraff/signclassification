{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open root directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = '/Users/brian/Documents/datasets/lisa_set'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of the-sub directories that have images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_dirs = [str(x) for x in os.listdir(root) if x[-1].isdigit()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all further sub-directories with images in them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "for direct in image_dirs:\n",
    "    for subdir in os.listdir(root+'/'+direct)[:]:\n",
    "        if subdir[0].isalpha():\n",
    "            image_paths.append(root+'/'+direct+'/'+subdir+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bounding = 'frameAnnotations.csv' # String name for the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting set: 0\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_0\n",
      "Finished set: 0\n",
      "Starting set: 1\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_1\n",
      "Finished set: 1\n",
      "Starting set: 2\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_2\n",
      "Finished set: 2\n",
      "Starting set: 3\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_3\n",
      "Finished set: 3\n",
      "Starting set: 4\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_4\n",
      "Finished set: 4\n",
      "Starting set: 5\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_5\n",
      "Finished set: 5\n",
      "Starting set: 6\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_6\n",
      "Finished set: 6\n",
      "Starting set: 7\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_7\n",
      "Finished set: 7\n",
      "Starting set: 8\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_8\n",
      "Finished set: 8\n",
      "Starting set: 9\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_9\n",
      "Finished set: 9\n",
      "Starting set: 10\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_10\n",
      "Finished set: 10\n",
      "Starting set: 11\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_11\n",
      "Finished set: 11\n",
      "Starting set: 12\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_12\n",
      "Finished set: 12\n",
      "Starting set: 13\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_13\n",
      "Finished set: 13\n",
      "Starting set: 14\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_14\n",
      "Finished set: 14\n",
      "Starting set: 15\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_15\n",
      "Finished set: 15\n",
      "Starting set: 16\n",
      "Creating path: /Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_16\n",
      "Finished set: 16\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(image_paths)):\n",
    "    make_images(i)\n",
    "    print \"Finished set: {}\".format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_images(current_ind):\n",
    "    print \"Starting set: \" + str(current_ind)\n",
    "    current = image_paths[current_ind]\n",
    "    images = [x for x in os.listdir(current) if '.png' in x]\n",
    "    image_annot = pd.read_csv(current+bounding, delimiter=';')\n",
    "\n",
    "    save_path = r'/Users/brian/Google Drive/Galvanize/course/capstone/signclassification/data/fullset/set_{}'.format(current_ind) \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        print \"Creating path: \" + save_path\n",
    "    with open('data/fullset/set_{}/path.txt'.format(current_ind), 'w') as f:\n",
    "        f.write(image_paths[i])\n",
    "\n",
    "    image_bounds_1 = {}\n",
    "    for row in range(len(image_annot)):\n",
    "        image_bounds_1[image_annot.loc[row][0]] = (image_annot.loc[row][1],[float(x) for x in str(image_annot.loc[row][2:6]).split() if x.isdigit()])\n",
    "\n",
    "    saved_images = []\n",
    "    for im in image_bounds_1.keys():\n",
    "        img = Image.open(current+im)\n",
    "        img2 = img.crop(tuple(image_bounds_1[im][1]))\n",
    "        longer_side = max(img2.size)\n",
    "        horizontal_padding = (longer_side - img2.size[0]) / 2\n",
    "        vertical_padding = (longer_side - img2.size[1]) / 2\n",
    "        img3 = img2.crop(\n",
    "        (\n",
    "            -horizontal_padding,\n",
    "            -vertical_padding,\n",
    "            img2.size[0] + horizontal_padding,\n",
    "            img2.size[1] + vertical_padding\n",
    "        )\n",
    "        )\n",
    "        if img3.size[0] > img3.size[1]:\n",
    "            img4 = img3.crop((0,0,img3.size[1],img3.size[1]))\n",
    "        elif img3.size[0] < img3.size[1]:\n",
    "            img4 = img3.crop((0,0,img3.size[0],img3.size[0]))\n",
    "        else:\n",
    "            img4 = img3\n",
    "        image_str = '{}{}'.format(image_bounds_1[im][0], str(img4.size))\n",
    "        x = 0\n",
    "        while image_str + str(x) in saved_images:\n",
    "            x += 1\n",
    "        image_str += str(x)\n",
    "        saved_images.append(image_str)\n",
    "        img4.save(\"./data/fullset/set_{}/{}.jpg\".format(current_ind, image_str))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.mapillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signs = db.signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signs_list = []\n",
    "for i in range(100):\n",
    "    signs_list.append(signs.find_one()['features'][i]['properties']['value'])\n",
    "signs_list = np.array(signs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_import-warning--road-narrows-right--us\n",
      "regulatory--dual-lanes-bicyclists-and-pedestrians--g1\n",
      "regulatory--no-entry--g1\n",
      "regulatory--no-equestrians--g1\n",
      "regulatory--no-left-turn--g1\n",
      "regulatory--no-parking--g2\n",
      "regulatory--no-right-turn--g1\n",
      "regulatory--no-u-turn--g1\n",
      "regulatory--stop--g1\n",
      "regulatory--yield--g1\n",
      "warning--added-lane-right--g1\n",
      "warning--curve-left--g2\n",
      "warning--curve-right--g2\n",
      "warning--double-curve-first-left--g2\n",
      "warning--double-curve-first-right--g2\n",
      "warning--double-turn-first-right--g1\n",
      "warning--height-restriction--g2\n",
      "warning--junction-with-a-side-road-acute-left--g1\n",
      "warning--loop-270-degree--g1\n",
      "warning--pedestrians-crossing--g4\n",
      "warning--road-narrows-left--g2\n",
      "warning--road-narrows-right--g2\n",
      "warning--slippery-road-surface--g2\n",
      "warning--texts--g2\n",
      "warning--texts--g3\n",
      "warning--traffic-merges-right--g1\n",
      "warning--traffic-signals--g3\n",
      "warning--turn-left--g1\n",
      "warning--turn-right--g1\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(signs_list):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Flickr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import re\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/brian/Documents/keys/flickr.txt') as f:\n",
    "    keys = f.read()\n",
    "keys = keys.split()\n",
    "key = re.search(r\"'([^']*?)'\",keys[0]).group().strip(\"'\")\n",
    "secret = re.search(r\"'([^']*?)'\",keys[1]).group().strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flickr = flickrapi.FlickrAPI(key,secret)\n",
    "photos = flickr.photos.search(tags='sybren,365,threesixtyfive', per_page='10', format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = flickr.photosets.getList(user_id='73509078@N00', format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_json = json.loads(sets)\n",
    "photos_j = json.loads(photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'can_comment': 0,\n",
       " u'count_comments': u'0',\n",
       " u'count_views': u'36',\n",
       " u'date_create': u'1475529863',\n",
       " u'date_update': u'1475530523',\n",
       " u'description': {u'_content': u'Photos I take en route to work.'},\n",
       " u'farm': 9,\n",
       " u'id': u'72157674639812906',\n",
       " u'needs_interstitial': 0,\n",
       " u'photos': u'7',\n",
       " u'primary': u'30014551651',\n",
       " u'secret': u'cfdd173178',\n",
       " u'server': u'8742',\n",
       " u'title': {u'_content': u'En Route'},\n",
       " u'videos': 0,\n",
       " u'visibility_can_see_set': 1}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_json['photosets']['photoset'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'farm': 4,\n",
       " u'id': u'33404189525',\n",
       " u'isfamily': 0,\n",
       " u'isfriend': 0,\n",
       " u'ispublic': 1,\n",
       " u'owner': u'144876000@N07',\n",
       " u'secret': u'551dfa8c9e',\n",
       " u'server': u'3767',\n",
       " u'title': u'70/365'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos_j['photos']['photo'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://farm{farm-id}.staticflickr.com/{server-id}/{id}_{secret}.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://farm6.staticflickr.com/5631/30014555241_cc74e7f525.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
